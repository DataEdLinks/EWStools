<!--
%\VignetteEngine{knitr}
%\VignetteIndexEntry{Simulated Data}
-->

```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(
  comment = "#>",
  error = FALSE,
  tidy = FALSE
)



```

# Introduction

The `EWStools` package is designed to automate many of the model building and 
checking tests that are common in predictive analytics, specifically for the 
education domain. To do this, let's work with a simple simulated dataset we can 
construct using the `twoClassSim` function in the `caret` package:

```{r builddata}
set.seed(442)
library(caret)
train <- twoClassSim(n = 1000, intercept = -8, linearVars = 3, 
                        noiseVars = 10, corrVars = 4, corrValue = 0.6)
test <- twoClassSim(n = 1500, intercept = -7, linearVars = 3, 
                       noiseVars = 10, corrVars = 4, corrValue = 0.6)

```

Let's see what this produces

```{r inspectdata}
head(train[, c(1:5, 20:23)])
table(train$Class)
```

Our training data has an imbalanced class structure and 22 predictors that are scaled 
and centered.

A key thing to note is that the `train` and `test` data have the exact same 
variable names and scales:

```{r compare}
names(train)
names(test)
```

Now let's build a model:

```{r buildexamplemodel}
ctrl <- trainControl(method = "repeatedcv", 
                     repeats = 3, classProbs = TRUE, 
                     summaryFunction = twoClassSummary)

fullModel <- train(Class ~ ., data = train, 
                   method = "knn", 
                   preProc = c("center", "scale"), 
                   tuneLength = 8, 
                   metric = "ROC", 
                   trControl = ctrl)

fullModel

```

# Conveniently Compare Accuracy